{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning with GCNs\n",
    "\n",
    "This tutorial is constructed from \n",
    " - A [google collab tutorial](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=NgcpV4rjAWy-) on graph neural networks.\n",
    " - A [second collab tutorial](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX) on node classification using graph neural networks \n",
    " - _Hands-On Graph Neural Networks Using Python_ Maxime Labonne, chapter 6\n",
    " - Lectures 6.1-6.4 from [Stanford machine learning course](https://www.youtube.com/watch?v=MH4yvtgAR-4)\n",
    " - a variety of other sources\n",
    "\n",
    "I don't know the copyright status of the collab code (none is listed on the pages), but you should check before you use it in anything beyond coursework.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Karate Club Network with Labeled Nodes_\n",
    "\n",
    "This part of the tutorial uses code liberally from the [google colab tutorial](https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=zF5bw3m9UrMy) on graph convolutional neural networks. I don't know the copyright status of this code (none is listed on the page), but you should check before you use it in anything beyond coursework. Note that this part of the tutorial doesn't do node classification, but we'll do that in the next part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 0  ##\n",
    "#############\n",
    "\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.data import Data as PyGData\n",
    "\n",
    "dataset = KarateClub()\n",
    "data: PyGData = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data object has x, edge_index, and y. Some have other information like the masks.  \n",
    "- x contains _node features_. The first index is the number of nodes, and the second index is the number of features. The cora database which we'll explore later has 2708 nodes each with a feature vector with 1433 components. The karate graph has 34 nodes and 34 features, discussed in the next cell.\n",
    "- y contains _node labels_. If our goal is to classify nodes then it helps to have some of the nodes labeled.\n",
    "- edge_index has _graph connectivity_. This is essentially the edge set of the graph. The first index contains the ordered edge pair. The second index is the number of edges. Each edge is directed, which means that an undirected graph with an edge $\\{u,v\\}$ appears wtice in the edge_index: once as $(u,v)$ and again as $(v,u)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some more information from the dataset, specifically node label information. The karate club data set uses a \"one-hot\" encoding of node features. We'll discuss other node features when we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KarateClub()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Classes.__ There are four classes. The karate club dataset from pytorch geometric has chosen four nodes and given them different labels. This was done so that any work that follows can try to group the other nodes into one of those classes, resulting in four communities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correct node labels = \\n\\t{data.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Features.__ 34 features reminds us that this dataset is using one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a GCN, but rather than creating a graph autoencoder we'll create a network that learns to label nodes. As with the autoencoder work from the previous tutorial, the workhorse will be the GCNConv class from pytorch geometric.\n",
    "\n",
    "__Initialization.__ The network architecture is\n",
    " - First hidden layers with 34 inputs and 4 outputs. \n",
    " - Second hidden layers with 4 inputs and 4 outputs. \n",
    " - Third hidden layers with 4 inputs and 2 outputs. \n",
    " - Output layer, which tries to take the output from the third hidden layer and force it to chose one of four classes. \n",
    "Notice that the initialization defines weighting functions that use existing functions from pytorch or pytorch_geometric. We just have to specify the dimensions of each layer. \n",
    "\n",
    "__Forward.__ The forward function takes a graph as input and computes the output by applying the weighting and squashing. The feature vector (x) and the graph (edge_index) are the inputs to the model. The function then proceeds to do the weighting and squashing required. The function returns two things: an estimate of class of each node (e.g., to which community it belongs) and the embedding, which is defined as the output of the last hidden layer after it was squashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 1  ##\n",
    "#############\n",
    "# Code from https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=H_VTFHd0uFz6\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    " \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.hidden_layer_1 = GCNConv(dataset.num_features, 4)\n",
    "        self.hidden_layer_2 = GCNConv(4, 4)\n",
    "        self.hidden_layer_3 = GCNConv(4, 2)\n",
    "        self.output_layer = Linear(2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.hidden_layer_1(x, edge_index)  # weight\n",
    "        h = h.tanh()                            # squash\n",
    "        h = self.hidden_layer_2(h, edge_index)  # weight\n",
    "        h = h.tanh()                            # squash\n",
    "        h = self.hidden_layer_3(h, edge_index)  # weight\n",
    "        h = h.tanh()                            # squash. Final GNN embedding space.\n",
    "                # Apply a final (linear) classifier.\n",
    "        out = self.output_layer(h)\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial weights for each layer and for the output are randomly chosen.  The initialization above set the random seed so that everyone who runs this code gets the same visualization. We are only interested in the two-dimensional embedding that is generated when we integrate features from the the three hop neighborhoods, so we'll ignore the other variable returned from the method. Note that the forward method is called by invoking the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 2  ##\n",
    "#############\n",
    "\n",
    "_, embedding = model(data.x, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')\n",
    "\n",
    "visualize_embedding(embedding, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the collab tutorial points out, we get pretty good separation even with random weights. This is because there is a ton of structural information available in three-hop neighborhoods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now do some training. We already discussed how the data object held features (x), eges (edge_index), and node labels (y), but it also dontains something called _train_mask_. Let's remind ourselves of what is in the data object and then inspect the training mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Cell 2.5  ##\n",
    "###############\n",
    "\n",
    "print(data)\n",
    "print(data.train_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training mask is just a vector of booleans, where _True_ means that we will use the data in the training process and _False_ means we won't.\n",
    "\n",
    "We have the same pipeline as before:\n",
    " - use the model on some input data\n",
    " - compute the loss\n",
    " - derive the gradients\n",
    " - update the parameters based on the gradients\n",
    "\n",
    " Look at the following code, and then'll discuss the _criterion_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 3  ##\n",
    "#############\n",
    "model = GCN()\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first big difference between this code and the code is the criterion used to compute the loss function. _Cross entropy loss_ is a method that computes an error signal between the labeled classes of nodes and the labels given by the network. The only thing that I'll mention about this loss function is that we typically take the output of the network and push it through a softmax operator. We talked about the softmax operator when we discussed node2vec and deepwalk. The key idea is that it tries to assign a probability to each of the possible labels that could given to the node given its input features.\n",
    "\n",
    "The other difference is that the loss function isn't computed using all of the data. Using \"out[data.train_mask]\" and \"data.y[data.train_mask]\" says that we'll only compute the loss function on a subset of the nodes. All nodes will be used to compute out and h, but the loss is based on just a subset of nodes. The labels for nodes not identified in the training mask are never used to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__\n",
    "\n",
    "Let's do some training steps and look at how the nodes shift around until we have clear clusters. We'll only visualize the embedding every 50 steps or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 4  ##\n",
    "#############\n",
    "for epoch in range(401):\n",
    "    loss, embedding = train(data)\n",
    "    if epoch % 50 == 0:\n",
    "        visualize_embedding(embedding, color=data.y, epoch=epoch, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collab tutorial celebrates the result, but the green and yellow nodes haven't clustered well. Let's talk about why this is a near result.\n",
    "\n",
    "First, note that we only used labels from four of the 33 nodes in the network to train the network, but we tested on the classes of all the nodes. Despite the small number of nodes used in training, we still get a small loss function (see the label at the bottom of each plot) and we see that nodes with similar labels have some clustering.\n",
    "\n",
    "Second, let's visually inspect how well the trained classifier performs. The output is a $n\\times 4$ matrix that assigns a 4D vector score to each node $n$. Let's run this through a softmax to give us some sense of the probability of each node belonging to each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 5  ##\n",
    "#############\n",
    "import numpy as np\n",
    "out, h = model(data.x, data.edge_index)\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "class_probabilities = np.round(softmax(out).detach().numpy(),2)\n",
    "print(class_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each node, let's find the index that has maximum probability and compare to the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Cell 46 ##\n",
    "#############\n",
    "true_class = data.y.detach().numpy()\n",
    "correct_count = 0\n",
    "for i in range(data.num_features):\n",
    "    if np.argmax(class_probabilities[i,:]) == true_class[i]: correct_count += 1\n",
    "print(f\"Succeeded {np.round(correct_count/34,2)*100}% of the time\")\n",
    "for i in range(data.num_features):\n",
    "    print(f\"Node i: estimated class is {np.argmax(class_probabilities[i,:])} and actual class is {true_class[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying to Les Miserables\n",
    "Let's apply the same pattern from the karate graph to the Les Miserables graph. We'll import the graph from networkx, convert it to a torch_geometric instance, make sure the features are set using one-hop encoding, and see what the clusters are. Doing so will allow us to compare the GCN model to node2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch import Tensor\n",
    "G = nx.les_miserables_graph()   # read les miserables network\n",
    "data = from_networkx(G)      # convert to pytorch data structure\n",
    "data.x = Tensor(np.eye(len(G)))  # labels features using one-hop encoding\n",
    "print(f\"les miserables data = {data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating our own node labels__\n",
    "\n",
    "Let's label a few nodes by finding communities using the Louvain method, finding the node within each community that has maximum degree, and labeling that node. This is the supervised part of semi-supervised learning; we use some method to label nodes, and then train a network to label other nodes using those labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "nodes_dict = community.best_partition(G)\n",
    "labeled_nodes = set()\n",
    "labeled_node_list = []\n",
    "for community in set(nodes_dict.values()):\n",
    "    nodes = [key for key,val in nodes_dict.items() if val == community]\n",
    "    SG = G.subgraph(nodes).copy()\n",
    "    plt.figure()\n",
    "    nx.draw_networkx(SG, pos = nx.spring_layout(SG, seed = 0), node_color = 'y', node_size = 800, with_labels=True, alpha = 0.8)\n",
    "    labeled_node, max_degree = None, 0\n",
    "    for node in nodes:\n",
    "        if SG.degree(node) > max_degree:\n",
    "            max_degree = SG.degree(node)\n",
    "            labeled_node = node\n",
    "    labeled_node_list.append(labeled_node)\n",
    "    title = f\"Subgraph of community centered on {labeled_node}\"\n",
    "    labeled_nodes.add(labeled_node)\n",
    "    plt.title(title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the training mask and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(G.nodes)\n",
    "mask = [False for node in G.nodes]\n",
    "i = 0\n",
    "for node in nodes_dict.keys():\n",
    "    if node in labeled_nodes:\n",
    "        mask[i] = True\n",
    "    i += 1\n",
    "data.y = torch.tensor(list(nodes_dict.values()), dtype=torch.uint8)\n",
    "data.train_mask = torch.tensor(mask, dtype=bool)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels_1, hidden_channels_2):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.hidden_layer_1 = GCNConv(len(G.nodes), hidden_channels_1)\n",
    "        self.hidden_layer_2 = GCNConv(hidden_channels_1, hidden_channels_2)\n",
    "        self.output_layer = Linear(hidden_channels_2, len(labeled_nodes))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.hidden_layer_1(x, edge_index)  # weight\n",
    "        h = h.relu()                            # squash\n",
    "        h = self.hidden_layer_2(h, edge_index)  # weight\n",
    "        h = h.relu()                            # squash\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.output_layer(h)\n",
    "\n",
    "        return out, h\n",
    "model = GCN(16,8)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some visualization and clustering helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "    colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    for class_number in set(nodes_dict.values()):\n",
    "        index_list = extract_nodes_by_class(data.y,class_number)\n",
    "        plt.scatter(z[index_list, 0], z[index_list, 1], s=70, c=colorlist[class_number])\n",
    "\n",
    "    _ = plt.legend(labeled_node_list,bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def extract_nodes_by_class(data,class_number):\n",
    "    index_list = []\n",
    "    for index, _ in enumerate(data):\n",
    "        if data[index] == class_number:\n",
    "            index_list.append(index)\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now display the true labels for each node in the embedding space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5001):\n",
    "    loss, embedding = train(data)\n",
    "visualize(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add edges into this embedding to get a feel for how the pieces fit together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "\n",
    "z = TSNE(n_components=2).fit_transform(embedding.detach().cpu().numpy())\n",
    "pos = nx.spring_layout(G)\n",
    "#print(pos)\n",
    "i=0\n",
    "for node in pos.keys():\n",
    "    #print(pos[node])\n",
    "    pos[node] = [z[i,0], z[i,1]]\n",
    "    i = i + 1\n",
    "plt.figure(figsize = (10, 10))\n",
    "labellist = list(nodes_dict.values())\n",
    "for class_number in set(nodes_dict.values()):\n",
    "        nodelist = [key for key,val in nodes_dict.items() if val == class_number]\n",
    "        positions = {key:val for key, val in pos.items() if key in nodelist}\n",
    "        node_sizes = [20 + 20*val for key, val in dict(G.degree).items() if key in nodelist]\n",
    "        nx.draw_networkx_nodes(G, pos=positions, nodelist=nodelist, \n",
    "                               node_size = node_sizes, node_color = colorlist[class_number], \n",
    "                               label=labeled_node_list[class_number])\n",
    "\n",
    "#for num, i in enumerate(zip(G.nodes, labellist)):\n",
    "#    n, l = i[0], i[1]\n",
    "#    nx.draw_networkx_nodes(G, pos, nodelist=n, node_size = 5, node_color = colorlist[num], label=l)\n",
    "nx.draw_networkx_edges(G, pos, width = 0.25)\n",
    "_ = plt.legend(bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that's the neatest visualization that we've seen so far of the Les Miserables graph.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora: A More sophisticated Example\n",
    "\n",
    "In this example, we'll be using the Cora database. See [summary here](https://paperswithcode.com/dataset/cora) and [Automating the Construction of Internet Portals with Machine Learning](https://link.springer.com/article/10.1023/A:1009953814988), A. McCallum et al. \n",
    "\n",
    "We'll be using pytorch and pytorch-geometric since they have neat implementations of the neural network components that aren't core to what is emphasized in class. It might be useful to get familiar with the [Planetoid class and graphs](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.Planetoid.html). Label dictionary taken from [medium article](https://medium.com/mlearning-ai/ultimate-guide-to-graph-neural-networks-1-cora-dataset-37338c04fe6f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the code below is copied from Lebonne, pp. 69-70. Do not share.\n",
    "# pip install torch\n",
    "# pip install torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch import Tensor\n",
    "# Download the dataset\n",
    "dataset = Planetoid(root=\".\",name=\"Cora\")\n",
    "# \"Cora has only one graph we can store in a dedicated data variable\", Lebonne p. 69\n",
    "data = dataset[0]\n",
    "# Get familiar with the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('----------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one graph with about 2,700 nodes. Each node is placed into one of seven classes. Each node also has a vector of features associated with it. The features are built on a technique called \"bag of words\". The basic building block of a bag-of-words model is a vector of words associated with all the nodes. Think of it like this. A network of computer science papers is created with one node per network and a directed edge between papers if the first paper cites the second. Someone went through the titles, abstracts, and maybe some other parts of the papers and identified important words. This set of words is the \"vocabulary\" associated with the network. Organize the vocabulary into an ordered data type like a vector. We'll call this the _vocabulary vector_.\n",
    "\n",
    "Each node in the network is then identified by looking at the words from the vocabulary that made it into the paper. Each node is assigned a vector/tensor of the same size as the vocabulary vector. We call the vector associated with the node a _feature tensor_. If the word in the $j^{\\rm th}$ element of the vocabulary vector is in the paper, then the $j^{\\rm th}$ element of the feature tensor is assigned a value of 1; otherwise the $j^{\\rm th}$ element of the feature vector is assigned a 0. Let's inspect one of the feature vectors form the Cora dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data a bit more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data object has x, edge_index, and y. Some have other information like the masks.  \n",
    "- x contains _node features_. The first index is the number of nodes, and the second index is the number of features. Thus, the cora database has 2708 nodes each with a feature vector with 1433 components.\n",
    "- y contains _node labels_. If our goal is to classify nodes then it helps to have some of the nodes be labeled.\n",
    "- edge_index has _graph connectivity_. This is essentially the edge set of the graph. The first index contains the ordered edge pair. The second index is the number of edges. Each edge is directed, which means that an undirected graph with an edge $\\{u,v\\}$ appears wtice in the edge_index: once as $(u,v)$ and again as $(v,u)$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the features more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The x member of the data class contains nodes and their features\n",
    "# The features are a \"bag of words\". Words were taken from descriptions of \n",
    "# the indexed papers. A \"1\" indicates that the word in the bag is on the \n",
    "# citation 0.\n",
    "print(f'Features 5-25 of node 0: {data.x[0][5:25]}')\n",
    "print(f'Features 200-255 of node 1: {data.x[1][200:255]}')\n",
    "print(f'Features 5-25 of node 2: {data.x[2][5:25]}')\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's inspect the labels more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The y member of the data class contains node classes.\n",
    "label_dict = {\n",
    "    0: \"Theory\",\n",
    "    1: \"Reinforcement_Learning\",\n",
    "    2: \"Genetic_Algorithms\",\n",
    "    3: \"Neural_Networks\",\n",
    "    4: \"Probabilistic_Methods\",\n",
    "    5: \"Case_Based\",\n",
    "    6: \"Rule_Learning\"}\n",
    "classes: list[int] = Tensor.tolist(data.y[:])\n",
    "print(f'Class of node 0: {label_dict[classes[0]]}')\n",
    "print(f'Class of node 1: {label_dict[classes[1]]}')\n",
    "print(f'Class of node 3: {label_dict[classes[3]]}')\n",
    "print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to visualize the graph to start to understand its structures. Using methods from [this article from Medium](https://medium.com/mlearning-ai/ultimate-guide-to-graph-neural-networks-1-cora-dataset-37338c04fe6f), we'll turn the data into a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "G = to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not connected, but I want to just see the largest component. Plotting the graph is slow in networkx, so I'm including three  options for you:\n",
    " - save the data as a gephi file so you can play with Gephi visualizations\n",
    " - plot positions using the spring layout (about a minute on my mac)\n",
    " - plot positions using the neato layout (about 1.5 minutes on my mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# pull out largest connected component\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "S= G.subgraph(largest_cc).copy()\n",
    "#nx.write_gexf(G, \"cora.gexf\")\n",
    "\n",
    "node_color = []\n",
    "nodelist = [[], [], [], [], [], [], []]\n",
    "colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "labels = data.y\n",
    "for n, i in enumerate(labels):\n",
    "    if n in S.nodes:\n",
    "        node_color.append(colorlist[i])\n",
    "        nodelist[i].append(n)\n",
    "#pos = nx.spring_layout(S, seed = 42)\n",
    "pos = nx.nx_pydot.graphviz_layout(S,prog=\"neato\") # slower than spring, but shows structure better\n",
    "plt.figure(figsize = (10, 10))\n",
    "labellist = list(label_dict.values())\n",
    "for num, i in enumerate(zip(nodelist, labellist)):\n",
    "    n, l = i[0], i[1]\n",
    "    nx.draw_networkx_nodes(S, pos, nodelist=n, node_size = 5, node_color = colorlist[num], label=l)\n",
    "nx.draw_networkx_edges(S, pos, width = 0.25)\n",
    "_ = plt.legend(bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure suggests that a common pattern for papers is that someone publishes an \"important\" paper that is then used in subsequent papers. This is pretty typical for work done in my lab; Students publish a paper to get things rolling, and then improve on the ideas in the paper while citing the first. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the visualization function from the [second collab tutorial](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX#scrollTo=imGrKO5YH11-). Note that the visualization function compresses whatever it is given into two dimensions. It uses the same compression tool we used when we discussed deepwalk and node2vec, namely TSNE.\n",
    "\n",
    "I've modified the visualization to use the label_dict dictionary and the colorlist defined above. This allows us to see a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    for class_number in label_dict.keys():\n",
    "        index_list = extract_nodes_by_class(data.y,class_number)\n",
    "        plt.scatter(z[index_list, 0], z[index_list, 1], s=70, c=colorlist[class_number], cmap=\"Set2\")\n",
    "\n",
    "    #plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    _ = plt.legend([\"Theory\", \"Reinforcement_Learning\", \"Genetic_Algorithms\",\n",
    "                    \"Neural_Networks\", \"Probabilistic_Methods\",\n",
    "                    \"Case_Based\", \"Rule_Learning\"],bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def extract_nodes_by_class(data,class_number):\n",
    "    index_list = []\n",
    "    for index, item in enumerate(data):\n",
    "        if data[index] == class_number:\n",
    "            index_list.append(index)\n",
    "    return index_list\n",
    "#print(extract_nodes_by_class(data.y,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collab tutorial has a neat aside where a traditional neural network is trained (a multilayer perceptron). The classification accuracy is lousy for two reasons. First, the data is not linearly separable (at least not easily so). Second, the MLP doesn't take advantage of the extra information available in the graph structures. _The information available in the graph structures is why graph machine learning can be very useful._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the collab tutorial and create a graph convolutional neural network with one hidden layer and one output layer. The hidden layer has dimension _hidden_channels_. This means that the low dimensional embedding has dimension equal to _hidden_channels_.  The hidden layer uses a rectified lineary unit, which effectually removes negative values from the matrix multiplications. Between the hidden layer and the output layer is a call to [F.dropout](https://pytorch.org/docs/stable/nn.functional.html#dropout-functions). My intuition about neural networks isn't strong enough to know why they do this, but I included it anyway. \n",
    "\n",
    "The output layer just computes the matrix multiplications. As before, I've renamed the the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.hidden = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.output = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.hidden(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.output(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden layer integrates one-hop neighborhoods, and the output layer does the matrix multiplication one more time to get two-hop neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "model.eval()\n",
    "\n",
    "embedding = model(data.x, data.edge_index)\n",
    "visualize(embedding, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not enough structure in the two hop neighborhoods to separate the nodes into classes without training.\n",
    "\n",
    "Let's train. Code is from the second collab tutorial. It is very close to what we did with the karate network, but I'd like to highlight a few differences.\n",
    " - Computing the loss only uses a subset of the data.\n",
    " - Testing how well the training performs also uses a subset of the data, but a different subset.\n",
    " - The output layer gives us seven numbers, and we choose the best one via the _argmax_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Javascript  # Restrict height of output cell.\n",
    "#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the loss goes down. Let's plot and see whether we have found good clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "embedding = model(data.x, data.edge_index)\n",
    "visualize(embedding, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding did indeed find communities. Nodes with similar labels grouped together. In order to do this, we used supervised learning, which means that someone had _supervised_ the learning by _labeling the nodes_. We then used that labeling to find the communities. The good news is that whoever did the labeling only had to label 5% of the nodes. Technically, this is called _semi-supervised_ learning -- a few labels, a lot of features, training and test sets, and exploiting graph structures to enable learning.  (Note that we actually knew all the labels, we just used a few of them to train. Without knowing the labels we wouldn't have been able to create the plot above.) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I leave this example, I just want to peak at what the graph looks like when we use the embedding above and add in the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = []\n",
    "nodelist = [[], [], [], [], [], [], []]\n",
    "colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
    "labels = data.y\n",
    "for n, i in enumerate(labels):\n",
    "    if n in S.nodes:\n",
    "        node_color.append(colorlist[i])\n",
    "        nodelist[i].append(n)\n",
    "\n",
    "pos = nx.spring_layout(S, seed = 42)\n",
    "z = TSNE(n_components=2).fit_transform(embedding.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos[1])\n",
    "for node in pos.keys():\n",
    "    pos[node] = z[node,:]\n",
    "print(pos[1])\n",
    "#pos = nx.nx_pydot.graphviz_layout(S,prog=\"neato\") # slower than spring, but shows structure better\n",
    "plt.figure(figsize = (10, 10))\n",
    "labellist = list(label_dict.values())\n",
    "for num, i in enumerate(zip(nodelist, labellist)):\n",
    "    n, l = i[0], i[1]\n",
    "    nx.draw_networkx_nodes(S, pos, nodelist=n, node_size = 5, node_color = colorlist[num], label=l)\n",
    "nx.draw_networkx_edges(S, pos, width = 0.05)\n",
    "_ = plt.legend(bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised learning with node similarity\n",
    "\n",
    "Leskovec says that you can blend feature-based learning in graph convolutional neural networks with similarity metrics like those used in deepwalk and node2vec. I won't show an example of that here, but check out [minute 28 of his course](https://www.youtube.com/watch?v=MH4yvtgAR-4).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
